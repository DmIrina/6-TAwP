{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('all')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "text_file = open(\"text5.txt\", \"r\")\n",
    "text = text_file.read()\n",
    "text_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[\"It was not very long before my friend's prediction was fulfilled.\",\n 'A\\nfortnight went by, during which I frequently found my thoughts turning\\nin her direction, and wondering what strange side-alley of human\\nexperience this lonely woman had strayed into.',\n 'The unusual salary,\\nthe curious conditions, the light duties, all pointed to something\\nabnormal, though whether a fad or a plot, or whether the man were\\na philanthropist or a villain, it was quite beyond my powers to\\ndetermine.',\n 'As to Holmes, I observed that he sat frequently for half an\\nhour on end, with knitted brows and an abstracted air, but he swept the\\nmatter away with a wave of his hand when I mentioned it.',\n '\"Data!',\n 'data!',\n 'data!\"',\n 'he cried, impatiently.',\n '\"I can\\'t make bricks without clay.\"',\n 'And\\nyet he would always wind up by muttering that no sister of his should\\never have accepted such a situation.',\n 'The telegram which we eventually received came late one night, just as\\nI was thinking of turning in, and Holmes was settling down to one of\\nthose all-night chemical researches which he frequently indulged in,\\nwhen I would leave him stooping over a retort and a test-tube at night,\\nand find him in the same position when I came down to breakfast in\\nthe morning.',\n 'He opened the yellow envelope, and then, glancing at the\\nmessage, threw it across to me.']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# text = ' Some perfect small small small sentences sentences  text Maybe Maybe perfect Maybe  ; sentences Maybe Maybe sentences. Maybe Maybe Maybe two! Or more , , three? No. more more more Maybe Maybe some sentences hi more is TEST a the text. The hello ,, my little text text text text sentences a cat there , which : cute perfect small   is cute.'\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "sents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "punct_list = [char for char in string.punctuation]\n",
    "stop_list = stopwords.words('english') + punct_list\n",
    "\n",
    "\n",
    "def clean_text_in_sentence(sentence):\n",
    "    clean_list = [word for word in sentence.lower().split() if word not in stop_list]\n",
    "    return clear_punc(clean_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clear_punc(txt_arr):\n",
    "    new_txt_arr = []\n",
    "    for txt_part in txt_arr:\n",
    "        new_txt = re.sub(r'[^\\w\\s]', '', txt_part)\n",
    "        if new_txt != \"\":\n",
    "            new_txt_arr.append(new_txt)\n",
    "    return new_txt_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'He opened the yellow envelope, and then, glancing at the\\nmessage, threw it across to me.'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_sen = sents[len(sents) - 1]\n",
    "last_sen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['opened',\n 'yellow',\n 'envelope',\n 'then',\n 'glancing',\n 'message',\n 'threw',\n 'across',\n 'me']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_last_sen = clean_text_in_sentence(last_sen)\n",
    "clean_last_sen"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кількість слів в останньому реченні: 9\n"
     ]
    }
   ],
   "source": [
    "print(\"Кількість слів в останньому реченні: \" + str(len(clean_last_sen)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. б)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def clean_text(text_sample):\n",
    "    new_text_arr = []\n",
    "    for sentence in sent_tokenize(text_sample):\n",
    "        sentence = clean_text_in_sentence(sentence)\n",
    "        for word in sentence:\n",
    "            new_text_arr.append(word)\n",
    "    return new_text_arr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long', 'friends', 'prediction', 'fulfilled', 'fortnight', 'went', 'by', 'frequently', 'found', 'thoughts', 'turning', 'direction', 'wondering', 'strange', 'sidealley', 'human', 'experience', 'lonely', 'woman', 'strayed', 'into', 'unusual', 'salary', 'curious', 'conditions', 'light', 'duties', 'pointed', 'something', 'abnormal', 'though', 'whether', 'fad', 'plot', 'whether', 'man', 'philanthropist', 'villain', 'quite', 'beyond', 'powers', 'determine', 'holmes', 'observed', 'sat', 'frequently', 'half', 'hour', 'end', 'knitted', 'brows', 'abstracted', 'air', 'swept', 'matter', 'away', 'wave', 'hand', 'mentioned', 'it', 'data', 'data', 'data', 'cried', 'impatiently', 'i', 'cant', 'make', 'bricks', 'without', 'clay', 'yet', 'would', 'always', 'wind', 'muttering', 'sister', 'ever', 'accepted', 'situation', 'telegram', 'eventually', 'received', 'came', 'late', 'one', 'night', 'thinking', 'turning', 'in', 'holmes', 'settling', 'one', 'allnight', 'chemical', 'researches', 'frequently', 'indulged', 'in', 'would', 'leave', 'stooping', 'retort', 'testtube', 'night', 'find', 'position', 'came', 'breakfast', 'morning', 'opened', 'yellow', 'envelope', 'then', 'glancing', 'message', 'threw', 'across', 'me']\n"
     ]
    }
   ],
   "source": [
    "text = clean_text(text)\n",
    "print(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.в)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def search_n_popular_words(num, txt):\n",
    "    word_stats = nltk.FreqDist(txt)\n",
    "    return word_stats.most_common(num)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "         Word  Frequency\n0  frequently          3\n1        data          3\n2     turning          2\n3     whether          2\n4      holmes          2\n5       would          2\n6        came          2\n7         one          2\n8       night          2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>frequently</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>data</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>turning</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>whether</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>holmes</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>would</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>came</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>one</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>night</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "freq = search_n_popular_words(9, text)\n",
    "pd.DataFrame(freq, columns=[\"Word\", \"Frequency\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/15220', 'test/15568', 'test/15643', 'test/15853', 'test/15871', 'test/15875', 'test/15876', 'test/15890', 'test/15906', 'test/15925', 'test/15973', 'test/16009', 'test/16107', 'test/18873', 'test/19570', 'test/19672', 'test/19835', 'test/19947', 'test/20019', 'test/21530', 'training/10062', 'training/104', 'training/10537', 'training/11064', 'training/11091', 'training/11507', 'training/11609', 'training/11640', 'training/11671', 'training/11769', 'training/11970', 'training/12254', 'training/12372', 'training/12969', 'training/1405', 'training/14354', 'training/1590', 'training/1882', 'training/235', 'training/2359', 'training/2456', 'training/2975', 'training/374', 'training/4056', 'training/4103', 'training/4231', 'training/4549', 'training/4679', 'training/5040', 'training/5467', 'training/5610', 'training/6063', 'training/6269', 'training/6535', 'training/7640', 'training/7917', 'training/8273', 'training/8413', 'training/8759']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "print(reuters.fileids(categories='cotton'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.а)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['WORLD MARKET PRICE FOR UPLAND COTTON - USDA The U . S . Agriculture Department announced the prevailing world market price , adjusted to U . S . quality and location , for Strict Low Middling , 1 - 1 / 16 inch upland cotton at 52 . 69 cts per lb , to be in effect through midnight March 5 .',\n 'The adjusted world price is at average U . S . producing locations ( near Lubbock , Texas ) and will be further adjusted for other qualities and locations .',\n 'The price will be used in determining First Handler Cotton Certificate payment rates .',\n 'Based on data for the week ended February 26 , the adjusted world price for upland cotton is determined as follows , in cts per lb -- Northern European Price 66 . 32 Adjustments -- Average U . S . spot mkt location 10 . 42 SLM 1 - 1 / 16 inch cotton 1 . 80 Average U . S . location 0 . 53 Sum of adjustments 12 . 75 Adjusted world price 53 . 57']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_lists = reuters.sents(fileids='training/104')\n",
    "\n",
    "sentences = [' '.join(sentence_tokens) for sentence_tokens in words_in_lists]\n",
    "sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "['WORLD MARKET PRICE FOR UPLAND COTTON - USDA The U . S . Agriculture Department announced the prevailing world market price , adjusted to U . S . quality and location , for Strict Low Middling , 1 - 1 / 16 inch upland cotton at 52 . 69 cts per lb , to be in effect through midnight March 5 .',\n 'The price will be used in determining First Handler Cotton Certificate payment rates .']"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[::2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.б)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[('WORLD', 'JJ'),\n ('MARKET', 'NNP'),\n ('PRICE', 'NNP'),\n ('FOR', 'NNP'),\n ('UPLAND', 'NNP'),\n ('COTTON', 'NNP'),\n ('-', ':'),\n ('USDA', 'VBZ'),\n ('The', 'DT'),\n ('U', 'NNP'),\n ('.', '.'),\n ('S', 'NNP'),\n ('.', '.'),\n ('Agriculture', 'NNP'),\n ('Department', 'NNP'),\n ('announced', 'VBD'),\n ('the', 'DT'),\n ('prevailing', 'JJ'),\n ('world', 'NN'),\n ('market', 'NN'),\n ('price', 'NN'),\n (',', ','),\n ('adjusted', 'VBN'),\n ('to', 'TO'),\n ('U', 'NNP'),\n ('.', '.'),\n ('S', 'NNP'),\n ('.', '.'),\n ('quality', 'NN'),\n ('and', 'CC'),\n ('location', 'NN'),\n (',', ','),\n ('for', 'IN'),\n ('Strict', 'NNP'),\n ('Low', 'NNP'),\n ('Middling', 'NNP'),\n (',', ','),\n ('1', 'CD'),\n ('-', ':'),\n ('1', 'CD'),\n ('/', '$'),\n ('16', 'CD'),\n ('inch', 'NN'),\n ('upland', 'JJ'),\n ('cotton', 'NN'),\n ('at', 'IN'),\n ('52', 'CD'),\n ('.', '.'),\n ('69', 'CD'),\n ('cts', 'NNS'),\n ('per', 'IN'),\n ('lb', 'NN'),\n (',', ','),\n ('to', 'TO'),\n ('be', 'VB'),\n ('in', 'IN'),\n ('effect', 'NN'),\n ('through', 'IN'),\n ('midnight', 'NN'),\n ('March', 'NNP'),\n ('5', 'CD'),\n ('.', '.'),\n ('The', 'DT'),\n ('adjusted', 'JJ'),\n ('world', 'NN'),\n ('price', 'NN'),\n ('is', 'VBZ'),\n ('at', 'IN'),\n ('average', 'JJ'),\n ('U', 'NNP'),\n ('.', '.'),\n ('S', 'NNP'),\n ('.', '.'),\n ('producing', 'VBG'),\n ('locations', 'NNS'),\n ('(', '('),\n ('near', 'IN'),\n ('Lubbock', 'NNP'),\n (',', ','),\n ('Texas', 'NNP'),\n (')', ')'),\n ('and', 'CC'),\n ('will', 'MD'),\n ('be', 'VB'),\n ('further', 'RB'),\n ('adjusted', 'VBN'),\n ('for', 'IN'),\n ('other', 'JJ'),\n ('qualities', 'NNS'),\n ('and', 'CC'),\n ('locations', 'NNS'),\n ('.', '.'),\n ('The', 'DT'),\n ('price', 'NN'),\n ('will', 'MD'),\n ('be', 'VB'),\n ('used', 'VBN'),\n ('in', 'IN'),\n ('determining', 'VBG'),\n ('First', 'NNP'),\n ('Handler', 'NNP'),\n ('Cotton', 'NNP'),\n ('Certificate', 'NNP'),\n ('payment', 'NN'),\n ('rates', 'NNS'),\n ('.', '.'),\n ('Based', 'VBN'),\n ('on', 'IN'),\n ('data', 'NNS'),\n ('for', 'IN'),\n ('the', 'DT'),\n ('week', 'NN'),\n ('ended', 'VBD'),\n ('February', 'NNP'),\n ('26', 'CD'),\n (',', ','),\n ('the', 'DT'),\n ('adjusted', 'JJ'),\n ('world', 'NN'),\n ('price', 'NN'),\n ('for', 'IN'),\n ('upland', 'JJ'),\n ('cotton', 'NN'),\n ('is', 'VBZ'),\n ('determined', 'VBN'),\n ('as', 'IN'),\n ('follows', 'VBZ'),\n (',', ','),\n ('in', 'IN'),\n ('cts', 'NNS'),\n ('per', 'IN'),\n ('lb', 'NN'),\n ('--', ':'),\n ('Northern', 'NNP'),\n ('European', 'NNP'),\n ('Price', 'NNP'),\n ('66', 'CD'),\n ('.', '.'),\n ('32', 'CD'),\n ('Adjustments', 'NNPS'),\n ('--', ':'),\n ('Average', 'JJ'),\n ('U', 'NNP'),\n ('.', '.'),\n ('S', 'NNP'),\n ('.', '.'),\n ('spot', 'NN'),\n ('mkt', 'NN'),\n ('location', 'NN'),\n ('10', 'CD'),\n ('.', '.'),\n ('42', 'CD'),\n ('SLM', 'NNP'),\n ('1', 'CD'),\n ('-', ':'),\n ('1', 'CD'),\n ('/', '$'),\n ('16', 'CD'),\n ('inch', 'JJ'),\n ('cotton', 'NN'),\n ('1', 'CD'),\n ('.', '.'),\n ('80', 'CD'),\n ('Average', 'JJ'),\n ('U', 'NNP'),\n ('.', '.'),\n ('S', 'NNP'),\n ('.', '.'),\n ('location', 'NN'),\n ('0', 'CD'),\n ('.', '.'),\n ('53', 'CD'),\n ('Sum', 'NNP'),\n ('of', 'IN'),\n ('adjustments', 'NNS'),\n ('12', 'CD'),\n ('.', '.'),\n ('75', 'CD'),\n ('Adjusted', 'JJ'),\n ('world', 'NN'),\n ('price', 'NN'),\n ('53', 'CD'),\n ('.', '.'),\n ('57', 'CD')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = reuters.words(fileids='training/104')\n",
    "pos_tagged = nltk.pos_tag(words)\n",
    "# pos_tagged = nltk.pos_tag(text)\n",
    "pos_tagged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[('USDA', 'VBZ'),\n ('announced', 'VBD'),\n ('adjusted', 'VBN'),\n ('be', 'VB'),\n ('is', 'VBZ'),\n ('producing', 'VBG'),\n ('be', 'VB'),\n ('adjusted', 'VBN'),\n ('be', 'VB'),\n ('used', 'VBN'),\n ('determining', 'VBG'),\n ('Based', 'VBN'),\n ('ended', 'VBD'),\n ('is', 'VBZ'),\n ('determined', 'VBN'),\n ('follows', 'VBZ')]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "filtered_verbs = [word for word in pos_tagged if word[1] in verb_tags]\n",
    "filtered_verbs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def get_verbs(items):\n",
    "    new_list = []\n",
    "    for i in range(0, len(items)):\n",
    "        new_list.append((items[i][0][0], items[i][1]))\n",
    "    return new_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "          Verb  Frequency\n0           be          3\n1     adjusted          2\n2           is          2\n3         USDA          1\n4    announced          1\n5    producing          1\n6         used          1\n7  determining          1\n8        Based          1\n9        ended          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Verb</th>\n      <th>Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>be</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adjusted</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USDA</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>announced</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>producing</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>used</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>determining</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Based</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ended</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = search_n_popular_words(10, filtered_verbs)\n",
    "pd.DataFrame(get_verbs(freq), columns=[\"Verb\", \"Frequency\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}